

# Step-by-Step Guide to Build a Serverless File Management System

## Project Description:

The Serverless File Management System automates the process of handling file uploads in the cloud. Whenever a user uploads a file to an Amazon S3 bucket, an AWS Lambda function is automatically triggered. This Lambda function extracts file metadata (like file name, size, and upload time) and stores it in Amazon DynamoDB for tracking and analysis. Optionally, an email notification is sent using Amazon SNS.

This project demonstrates a serverless cloud architecture ‚Äî no servers to manage, only managed services.

-Use Cases

1. Automated File Tracking:
Companies can automatically log every file uploaded to cloud storage ‚Äî useful for auditing, analytics, or compliance.


2. Cloud Backup Management:
Whenever files are uploaded to an S3 bucket, their details are stored for recovery or version control purposes.


3. Data Processing Pipelines:
Lambda triggers can initiate ETL jobs or downstream data pipelines (e.g., notifying a data analytics system).


4. Email Notification System:
Using SNS, stakeholders get notified when new files are uploaded ‚Äî helpful in multi-user or multi-department environments.


## Project Architecture

Architecture Components:

Amazon S3 ‚Äî File storage and event source.

AWS Lambda ‚Äî Processes metadata automatically upon file upload.

Amazon DynamoDB ‚Äî Stores metadata (file name, size, upload time).

Amazon SNS (optional) ‚Äî Sends email alerts for each new upload.

Amazon CloudWatch ‚Äî Monitors logs for Lambda executions.


Architecture Flow:
1Ô∏è‚É£ User uploads file to S3 ‚Üí
2Ô∏è‚É£ S3 triggers Lambda ‚Üí
3Ô∏è‚É£ Lambda extracts metadata ‚Üí
4Ô∏è‚É£ Metadata is stored in DynamoDB ‚Üí
5Ô∏è‚É£ (Optional) SNS sends notification email ‚Üí
6Ô∏è‚É£ Logs are captured in CloudWatch


## Prerequisites

‚úÖ AWS account with permissions for S3, Lambda, DynamoDB, SNS, and CloudWatch
‚úÖ Basic knowledge of Python and AWS Console
‚úÖ Installed AWS CLI (optional, for testing)


## Step-by-Step Deployment

Step 1 ‚Äî Create an S3 Bucket

Go to AWS Console ‚Üí S3 ‚Üí Create Bucket

Name: serverless-file-bucket-sid

Region: ap-south-1

Leave default settings ‚Üí click Create Bucket




Step 2 ‚Äî Create DynamoDB Table

Go to AWS Console ‚Üí DynamoDB ‚Üí Create Table

Table name: FileMetadata

Partition key: FileName (String)

Keep default settings ‚Üí click Create




Step 3 ‚Äî Create Lambda Function

Go to AWS Lambda ‚Üí Create Function

Name: FileMetadataHandler

Runtime: Python 3.12

Create new role with basic Lambda + DynamoDB + SNS permissions

Click Create Function


Add the following Python code:

import boto3
import json

dynamodb = boto3.resource('dynamodb')
sns = boto3.client('sns')

TABLE_NAME = 'FileMetadata'
SNS_TOPIC_ARN = 'arn:aws:sns:ap-south-1:YOUR_ACCOUNT_ID:file-upload-alerts'

def lambda_handler(event, context):
    print("Event received:", json.dumps(event))
    
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        file_name = record['s3']['object']['key']
        file_size = record['s3']['object']['size']
        event_time = record['eventTime']
        
        # Store metadata in DynamoDB
        table = dynamodb.Table(TABLE_NAME)
        response = table.put_item(
            Item={
                'FileName': file_name,
                'BucketName': bucket,
                'FileSize': file_size,
                'UploadTime': event_time
            }
        )
        print("Metadata stored successfully:", response)
        
        # Send SNS Notification
        message = f"üìÇ New file uploaded!\n\nFile: {file_name}\nBucket: {bucket}\nSize: {file_size} bytes\nUploaded at: {event_time}"
        sns.publish(
            TopicArn=SNS_TOPIC_ARN,
            Message=message,
            Subject="New File Upload Alert"
        )
        print("SNS notification sent successfully!")

    return {
        'statusCode': 200,
        'body': json.dumps('File processed successfully!')
    }



Step 4 ‚Äî Add S3 Trigger

In Lambda function ‚Üí Configuration ‚Üí Triggers ‚Üí Add trigger

Select S3

Choose bucket: serverless-file-bucket-sid

Event type: All object create events

Enable trigger ‚Üí Save




Step 5 ‚Äî Create SNS Topic (Optional)

Go to SNS ‚Üí Create Topic ‚Üí Standard

Name: file-upload-alerts

Copy the Topic ARN

Subscribe with your email ID ‚Üí confirm the subscription via email.

Replace ARN in the Lambda code (SNS_TOPIC_ARN value).




Step 6 ‚Äî Upload Test File

Go to your S3 bucket

Click Upload ‚Üí Add file ‚Üí Banking.csv (or any file)

Upload it and wait a few seconds



Step 7 ‚Äî Verify Outputs

‚úÖ Go to CloudWatch Logs ‚Üí check Lambda execution logs
‚úÖ Go to DynamoDB Table ‚Üí confirm new record added
‚úÖ Check email inbox (if SNS added) ‚Üí see upload alert



## Sample Output Log (CloudWatch)

Event received: {"Records": [{"eventSource": "aws:s3", "eventName": "ObjectCreated:Put"}]}
New file uploaded: Banking.csv in bucket: serverless-file-bucket-sid
Metadata stored successfully
SNS notification sent successfully!



## Cloud Concepts Demonstrated

Serverless Architecture ‚Äî Fully managed, auto-scaling, event-driven.

Event-driven Computing ‚Äî S3 triggers Lambda automatically.

NoSQL Data Storage ‚Äî DynamoDB used for fast metadata storage.

Monitoring & Observability ‚Äî CloudWatch logs show Lambda execution.

Decoupled Services ‚Äî Each AWS service operates independently yet integrates seamlessly.




## Real-World Application Example

A Digital Media Company uses this setup to automatically log and notify teams whenever new images, videos, or reports are uploaded by photographers or content creators.
This ensures automated tracking, centralized metadata management, and instant alerts, improving workflow transparency and reducing manual tracking.



## Final Outcome

 Automated, secure, and serverless file management pipeline.
 Upload a file ‚Üí triggers Lambda ‚Üí stores metadata ‚Üí sends email.
 Scalable, event-driven, and production-ready design
